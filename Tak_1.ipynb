{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blSr5YZ6YCsw",
        "outputId": "e50e1d0c-16f6-46b8-f01d-17395088ffe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: Extract\n",
            "ðŸ”¹ Raw Data:\n",
            "   CustomerID   Age  Gender     Category  Purchase\n",
            "0         101  25.0    Male  Electronics     300.0\n",
            "1         102  35.0  Female     Clothing     150.0\n",
            "2         103   NaN  Female     Clothing     200.0\n",
            "3         104  45.0    None  Electronics     250.0\n",
            "4         105  28.0    Male    Furniture       NaN\n",
            "STEP 2: Transform\n",
            "STEP 3: Load\n",
            "\n",
            "âœ… Transformed Feature Matrix (X):\n",
            "[[-1.19893036  0.          1.          0.          0.          1.\n",
            "   0.        ]\n",
            " [ 0.25431856  1.          0.          0.          1.          0.\n",
            "   0.        ]\n",
            " [ 0.          1.          0.          0.          1.          0.\n",
            "   0.        ]\n",
            " [ 1.70756748  0.          0.          1.          0.          1.\n",
            "   0.        ]\n",
            " [-0.76295568  0.          1.          0.          0.          0.\n",
            "   1.        ]]\n",
            "\n",
            "âœ… Target Vector (y):\n",
            "[300. 150. 200. 250. 225.]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print( \"STEP 1: Extract\" )\n",
        "# Simulate raw data\n",
        "data = {\n",
        "    'CustomerID': [101, 102, 103, 104, 105],\n",
        "    'Age': [25, 35, None, 45, 28],\n",
        "    'Gender': ['Male', 'Female', 'Female', None, 'Male'],\n",
        "    'Category': ['Electronics', 'Clothing', 'Clothing', 'Electronics', 'Furniture'],\n",
        "    'Purchase': [300, 150, 200, 250, None]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"ðŸ”¹ Raw Data:\")\n",
        "print(df)\n",
        "\n",
        "print(\"STEP 2: Transform\")\n",
        "# Features & Target\n",
        "X = df.drop(['CustomerID', 'Purchase'], axis=1)\n",
        "y = df['Purchase']\n",
        "\n",
        "# Define column types\n",
        "numeric_features = ['Age']\n",
        "categorical_features = ['Gender', 'Category']\n",
        "\n",
        "# Pipelines\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine into a ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "print(\"STEP 3: Load\")\n",
        "# Fit and transform\n",
        "X_clean = preprocessor.fit_transform(X)\n",
        "\n",
        "print(\"\\nâœ… Transformed Feature Matrix (X):\")\n",
        "# Check if X_clean is a sparse matrix before calling toarray() (though in this case it's dense)\n",
        "print(X_clean.toarray() if hasattr(X_clean, 'toarray') else X_clean)\n",
        "\n",
        "# Handle target column (drop NA)\n",
        "y_clean = y.fillna(y.mean())\n",
        "\n",
        "print(\"\\nâœ… Target Vector (y):\")\n",
        "print(y_clean.values)\n",
        "\n",
        "# Optional: Split and save\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save transformed data\n",
        "# X_train is already a dense numpy array, no need for toarray()\n",
        "pd.DataFrame(X_train).to_csv(\"X_train.csv\", index=False)\n",
        "pd.DataFrame(y_train).to_csv(\"y_train.csv\", index=False)"
      ]
    }
  ]
}